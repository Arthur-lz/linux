## 目录组织
|文件名|说明|
|:-|:-|
|KeyLink.md|fio, ftrace|
|debug|内核调试相关|

## linux内核文件的区别(vmlinux、zImage、bzImage、uImage、vmlinuz、initrd )
|内核|说明|
|:-|:-|
|vmlinux|  编译出来的最原始的内核文件，未压缩。
|zImage |  是vmlinux经过gzip压缩后的文件。
|bzImage| bz表示“big zImage”，不是用bzip2压缩的。两者的不同之处在于，zImage解压缩内核到低端内存(第一个640K)，bzImage解压缩内核到高端内存(1M以上)。如果内核比较小，那么采用zImage或bzImage都行，如果比较大应该用bzImage。
|uImage|   U-boot专用的映像文件，它是在zImage之前加上一个长度为0x40的tag。
|vmlinuz|  是bzImage/zImage文件的拷贝或指向bzImage/zImage的链接。
|initrd |  是“initial ramdisk”的简写。一般被用来临时的引导硬件到实际内核vmlinuz能够接管并继续引导的状态。

## 内存
### MMU
* 操作数据的最小单位是页
* CPU不同（即体系结构不同），CPU支持的页大小也不同，有4KB, 8KB, 16KB等，Intel的至强处理器可以支持2MB和1GB的大页
> 4KB的小页效率低，会浪费过多的page_struct结构实例来管理它

* kernel默认页大小是4KB 

#### TLB
* TLB位于MMU内部，它是一块高速缓存，用来保存页表转换结果，即CPU判断某个虚拟地址是否有效，会首先查TLB，如果TLB中有此虚拟地址，则直接从TLB里找到虚拟地址对应的物理地址来使用。否则，就称TLB未命中，此时MMU会负责去查找页面表，找到后将其存到TLB，同时给CPU使用。

#### 物理内存到虚拟内存
* mm_struct里的PGD成员保存了一级页表基址
* 以ARM体系结构的CPU为例来说明，虚拟地址到物理地址转换流程
> ARM是二级页表结构，虚拟地址位宽为32位

> 31至20位（高12位）用于存一级页表索引, 一级页表项中保存着二级页表基址, 一级页表总共有4096个页表项
  TTBRx寄存器中保存一级页表基地址

> 19至12位（中间的8位）用于存二级页表索引，二级页表项中保存着物理页面基址，二级页表总共有256个页表项

> 11至0位(低12位)用于在物理页面中定位到具体是哪个字节(因为这12位正好可以寻址4096，即一页大小)

* 进程内部由许多VMA结构（代码段VAM，数据段VMA，堆VMA，malloc的VMA, mmap的VMA等）组成，它代表进程的虚拟地址，其对应的物理地址，在实际需要时，通过CPU中的MMU硬件来实现虚拟与物理地址一一对应。

> VMA是基于分页机制来实现的，进程所占用的内存使用以页为单位的虚拟内存来管理，这样当系统内存不足/进程上下文切换时，系统可以以页为单位只回收进程所占用的部分内存，这比分段机制换出整个进程来说粒度更细效率更高。

* 内核中的内存地址？
> 内核空间虚拟地址／逻辑地址
  
### 内存的申请、释放
#### 伙伴系统
> 管理的是物理内存, 其各种内核函数返回的地址，有strutc page * ，有内核虚拟地址（或称逻辑地址, 也有称作线性地址），这些都不是物理地址，
  内存的物理地址可以通过内核函数virt_to_pfn来得到

##### alloc_pages
* 申请的物理页面是连续的，页面数量是2的order次方，申请成功返回第一页面的page结构指针
* get_page_from_freelist, 从空闲链表中分配页面
* zone_wartermark_ok, 判断系统当前zone的watermark水位是否充足
* buffered_rmqueue
* \__rmqueue_smallest, order > 0, 走此函数从伙伴系统分配页面
  order == 0则从zone->pageset列表中分配, 其是一个CPU高速缓存
* free_area数组

##### \__get_free_pages
* 申请成功返回的是第一个页面的逻辑地址（即内核虚拟地址）

##### 页面回收
* 将回收的页面进行合并组成大的连续的内存，合并内存有以下三个原则，
> 1、必须是由同一个大块内存分割而来

> 2、两个内存块必须是物理地址连续

> 3、两个内存块大小必须相同

* \__free_pages
  核心功能将页面添加到伙伴系统适当的free_area链表中 
  在释放内存块时，查询相邻内存块是否空闲，如果也空闲则合并成一个大的内存块，并放到高一阶的空闲链表free_area中。如果还能继续合并邻近的内存块，
  那么继续合并，并转移到高阶空闲链表，这个过程会重复下去，直到所有可能合并都已经合并为止。

* \__free_one_page
* page_is_buddy, 判断内存块是空闲，并且order值也相同，那么找到了可以合并的伙伴

* 内存碎片与内存规整
  内存规整就是利用移动页面的位置让空闲页面连成一片。

* 反碎片法
  从2.6.24引入了防止碎片的功能反碎片法
> 相关概念：
  迁移类型, 按照迁移类型不同，可以分为“不可迁移类型页面”、“可迁移类型页面”、“可回收的页面”这三类
  页块大小是页面分配器最大的分配大小，即2的MAX_ORDER-1次方，通常是4MB
  free_area[MAX_ORDER], 其每一个成员中有三种不同迁移类型的链表用来存储对应的页面, 每一种类型有2的order次方个页块 

> 在使用这种技术的内核中，所有的页块里面的页面都是同一迁移类型的，中间不会有其他类型的页面，所以不会出现早期内核版本中那种因内核申请的内存是不可迁移的导致无法合并成一块大内存。   

##### 查看系统当前分配的页类型使用状态
cat /proc/pagetypeinfo
> 可以知道当前系统page block 大小, 每种迁移类型在不同node上空闲页面数量
  
#### slab
* slab系统包括：
  描述符，节点，本地对象内存池（每个CPU一个），共享对象内存池（只有一个，多个CPU共享），三个链表（部分空闲、全部空闲、full），N个slab实例，
  众多slab对象

* 一个slab最大是2^25次方，即32MB 
* 基于伙伴系统
* kmem_cache_create用于创建slab描述符
> 申请定制大小、对齐方式的内存需要自己定义一个新的slab描述符

* kmem_cache_alloc用于创建slab缓存对象, 其内部关中断完成此操作
* kmem_cache_free用于释放slab缓存对象
* 每一个slab由一到N个连续页面组成，创建slab描述符时会计算一个slab需要战胜多少个页面，一个slab里有多少个slab对象，多少个cache colour.

* 在创建slab描述符时不会立即分配物理内存给slab实例，需要等到有进程申请使用slab对象时，这时内核才会判断如果slab三个链表没有空闲对象，且slab本地和共享缓存池都是空的时，才会给这个slab实例分配物理内存, 并将slab挂到slabs_free链表。
                
##### kmalloc
* 申请通用内存
* 按字节申请，申请成功返回内存逻辑地址
* 在系统启动时通过create_kmalloc_caches函数生成2^4~2^25次方字节的slab描述符


#### numa（与uma相对应，uma是所有CPU通过总线共享同一内存）
* 非一致内存访问, 每个CPU有与其对应的内存
* 用node结点来管理每一个CPU上的内存，每一个node上分为多个不同的zone（DMA, DMA32, normal）
